{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import librosa \nfrom librosa import display\nimport pylab as plt\nimport os\nimport pandas as pd\nimport glob\nimport numpy as np\nfrom numpy import savetxt\nfrom numpy import asarray\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:52:05.039082Z","iopub.execute_input":"2021-11-14T11:52:05.039369Z","iopub.status.idle":"2021-11-14T11:52:05.046144Z","shell.execute_reply.started":"2021-11-14T11:52:05.039339Z","shell.execute_reply":"2021-11-14T11:52:05.045242Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Create the dataframe of the RAVEDESS database.","metadata":{}},{"cell_type":"code","source":"path ='../input/ravdess/RAVDESS'\nemotion = []\nemotion_code =[]\ngender = []\nactor = []\nfile_path = []\nfor subdir,dirs,files in os.walk(path):\n    for file in files:\n        part = file.split('.')[0].split('-')\n        emotion.append(int(part[2]))\n        emotion_code.append(int(part[2]))\n        actor.append(int(part[6]))\n        bg = int(part[6])\n        if bg%2 == 0:\n            bg = \"female\"\n        else:\n            bg = \"male\"\n        gender.append(bg)\n        file_path.append('../input/ravdess/RAVDESS/' + file)\naudio_df = pd.DataFrame(emotion)\naudio_df = audio_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\naudio_df = pd.concat([pd.DataFrame(gender),pd.DataFrame(emotion_code),audio_df,pd.DataFrame(actor)],axis=1)\naudio_df.columns = ['gender','emotion_code','emotion','actor']\naudio_df = pd.concat([audio_df,pd.DataFrame(file_path, columns = ['path'])],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:52:05.048337Z","iopub.execute_input":"2021-11-14T11:52:05.048645Z","iopub.status.idle":"2021-11-14T11:52:05.720737Z","shell.execute_reply.started":"2021-11-14T11:52:05.048608Z","shell.execute_reply":"2021-11-14T11:52:05.719930Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Load all data and transform them into mel_spectrogram data","metadata":{}},{"cell_type":"code","source":"print(\"Hold on, loading data...\")\ndf = pd.DataFrame(columns=['mel_spectrogram'])\ncounter=0\nfor index,path in enumerate(audio_df.path):\n    X, sample_rate = librosa.load(path, res_type='kaiser_fast',duration=3,sr=44100,offset=0.5)\n    \n    #get the mel-scaled spectrogram (ransform both the y-axis (frequency) to log scale, and the “color” axis (amplitude) to Decibels, which is kinda the log scale of amplitudes.)\n    spectrogram = librosa.feature.melspectrogram(y=X, sr=sample_rate, n_mels=128,fmax=8000) \n    db_spec = librosa.power_to_db(spectrogram)\n    df.loc[counter] = [db_spec]\n    counter=counter+1\n    \naudio_df['mel_spectrogram']= df['mel_spectrogram']","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:52:05.722438Z","iopub.execute_input":"2021-11-14T11:52:05.722983Z","iopub.status.idle":"2021-11-14T11:55:34.800667Z","shell.execute_reply.started":"2021-11-14T11:52:05.722943Z","shell.execute_reply":"2021-11-14T11:55:34.799761Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df2 = audio_df","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:34.802471Z","iopub.execute_input":"2021-11-14T11:55:34.803032Z","iopub.status.idle":"2021-11-14T11:55:34.807112Z","shell.execute_reply.started":"2021-11-14T11:55:34.802991Z","shell.execute_reply":"2021-11-14T11:55:34.806358Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Drop the inconsistent data","metadata":{}},{"cell_type":"code","source":"to_drop = []\nfor i in range(2452):\n    if df2['mel_spectrogram'].iloc[i].shape[1]!=259:\n        to_drop.append(i)\n\ndf2 = df2.drop(to_drop)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:34.809968Z","iopub.execute_input":"2021-11-14T11:55:34.811148Z","iopub.status.idle":"2021-11-14T11:55:34.875569Z","shell.execute_reply.started":"2021-11-14T11:55:34.811106Z","shell.execute_reply":"2021-11-14T11:55:34.874790Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Split the dataset into 8/2 ratio ","metadata":{}},{"cell_type":"code","source":"train,test = train_test_split(df2,test_size=0.2)\ntemp_X_train = train.iloc[:,5]\ntemp_X_test = test.iloc[:,5]\n\ny_train = train.iloc[:,1]\ny_test = test.iloc[:,1]\n\nX_train = []\nX_test = []\n\nfor i in range(temp_X_train.shape[0]):\n    X_train.append(temp_X_train.iloc[i])\n\nX_train = np.array(X_train)\n\nfor i in range(temp_X_test.shape[0]):\n    X_test.append(temp_X_test.iloc[i])\n\nX_test = np.array(X_test)\n\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:34.880189Z","iopub.execute_input":"2021-11-14T11:55:34.880832Z","iopub.status.idle":"2021-11-14T11:55:35.013333Z","shell.execute_reply.started":"2021-11-14T11:55:34.880788Z","shell.execute_reply":"2021-11-14T11:55:35.012606Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"a dummy classifer to test the initial database","metadata":{}},{"cell_type":"code","source":"dummy_clf = DummyClassifier()\ndummy_clf.fit(X_train, y_train)\nDummyClassifier()\ndummy_clf.predict(X_test)\nprint(dummy_clf.score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:35.014719Z","iopub.execute_input":"2021-11-14T11:55:35.014975Z","iopub.status.idle":"2021-11-14T11:55:35.026532Z","shell.execute_reply.started":"2021-11-14T11:55:35.014939Z","shell.execute_reply":"2021-11-14T11:55:35.023897Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:35.028129Z","iopub.execute_input":"2021-11-14T11:55:35.028393Z","iopub.status.idle":"2021-11-14T11:55:35.083180Z","shell.execute_reply.started":"2021-11-14T11:55:35.028360Z","shell.execute_reply":"2021-11-14T11:55:35.082274Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_train = torch.from_numpy(X_train) \ny_train = torch.from_numpy(np.asarray(y_train)) \nX_test = torch.from_numpy(X_test) \ny_test = torch.from_numpy(np.asarray(y_test)) ","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:35.086612Z","iopub.execute_input":"2021-11-14T11:55:35.087201Z","iopub.status.idle":"2021-11-14T11:55:35.095804Z","shell.execute_reply.started":"2021-11-14T11:55:35.087167Z","shell.execute_reply":"2021-11-14T11:55:35.094913Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"we minus 1 from all values in the labels, as the database labels are from 1 to 8, but to standardize, we change them to 0 to 7","metadata":{}},{"cell_type":"code","source":"print(X_train.size())\nprint(y_train.size())\n\ny_train = y_train-1\ny_test = y_test-1","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:35.097326Z","iopub.execute_input":"2021-11-14T11:55:35.097847Z","iopub.status.idle":"2021-11-14T11:55:35.122983Z","shell.execute_reply.started":"2021-11-14T11:55:35.097807Z","shell.execute_reply":"2021-11-14T11:55:35.122261Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(max(y_train))\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:35.124365Z","iopub.execute_input":"2021-11-14T11:55:35.124813Z","iopub.status.idle":"2021-11-14T11:55:35.156367Z","shell.execute_reply.started":"2021-11-14T11:55:35.124775Z","shell.execute_reply":"2021-11-14T11:55:35.155253Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Calcualte the mean","metadata":{}},{"cell_type":"code","source":"mean= X_train.mean()\n\nprint(mean)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:35.157589Z","iopub.execute_input":"2021-11-14T11:55:35.157903Z","iopub.status.idle":"2021-11-14T11:55:35.216113Z","shell.execute_reply.started":"2021-11-14T11:55:35.157866Z","shell.execute_reply":"2021-11-14T11:55:35.215358Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Calculate the standard deviation for the normalizing steps later","metadata":{}},{"cell_type":"code","source":"std= X_train.std()\n\nprint(std)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T11:55:35.217287Z","iopub.execute_input":"2021-11-14T11:55:35.217683Z","iopub.status.idle":"2021-11-14T11:55:35.319075Z","shell.execute_reply.started":"2021-11-14T11:55:35.217647Z","shell.execute_reply":"2021-11-14T11:55:35.318166Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"net = nn.Sequential(\n        nn.Conv2d(1,   50,  kernel_size=3,  padding=1 ),\n        nn.BatchNorm2d(50),\n        nn.ReLU(inplace = True),\n        nn.MaxPool2d(2,2),\n       \n        nn.Conv2d(50, 100,  kernel_size=3,  padding=1 ),\n        nn.Dropout(0.5),\n        nn.ReLU(inplace = True),\n        nn.MaxPool2d(2,2),\n        nn.Flatten(start_dim=1),\n        nn.Linear(204800, 100),\n        nn.ReLU(inplace=True),\n        nn.Linear(100,8),\n)\nnet = net.to(device)\n\nmean=mean.to(device)\n\nstd=std.to(device)\ncriterion = nn.CrossEntropyLoss()\n\nmy_lr=0.001\n\nbs= 10","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:02:45.394729Z","iopub.execute_input":"2021-11-14T12:02:45.395178Z","iopub.status.idle":"2021-11-14T12:02:45.584822Z","shell.execute_reply.started":"2021-11-14T12:02:45.395139Z","shell.execute_reply":"2021-11-14T12:02:45.584008Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"get error function to evaluate the network","metadata":{}},{"cell_type":"code","source":"def get_error( scores , labels ):\n\n    bs=scores.size(0)\n    predicted_labels = scores.argmax(dim=1)\n    #print(predicted_labels)\n    indicator = (predicted_labels == labels)\n    num_matches=indicator.sum()\n    \n    return 1-num_matches.float()/bs ","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:02:47.497431Z","iopub.execute_input":"2021-11-14T12:02:47.497978Z","iopub.status.idle":"2021-11-14T12:02:47.502800Z","shell.execute_reply.started":"2021-11-14T12:02:47.497942Z","shell.execute_reply":"2021-11-14T12:02:47.501580Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def eval_on_test_set():\n\n    running_error=0\n    num_batches=0\n\n    for i in range(0,415,bs):\n\n        minibatch_data =  X_test[i:i+bs].unsqueeze(dim=1)\n        minibatch_label= y_test[i:i+bs]\n\n        minibatch_data=minibatch_data.to(device)\n        minibatch_label=minibatch_label.to(device)\n        \n        inputs = (minibatch_data - mean)/std   \n\n        scores=net( inputs ) \n\n        error = get_error( scores , minibatch_label)\n\n        running_error += error.item()\n\n        num_batches+=1\n\n\n    total_error = running_error/num_batches\n    return total_error","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:02:49.171234Z","iopub.execute_input":"2021-11-14T12:02:49.171532Z","iopub.status.idle":"2021-11-14T12:02:49.178624Z","shell.execute_reply.started":"2021-11-14T12:02:49.171503Z","shell.execute_reply":"2021-11-14T12:02:49.177747Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"training_error = []\ntesting_error = []\n\nfor epoch in range(1,60):\n    \n    if not epoch%5:\n        my_lr = my_lr / 1.5\n        \n    optimizer=torch.optim.SGD( net.parameters() , lr=my_lr )\n        \n    running_loss=0\n    running_error=0\n    num_batches=0\n    \n    shuffled_indices=torch.randperm(1660)\n \n    for count in range(0,1660,bs):\n        \n        \n    \n        optimizer.zero_grad()\n             \n        indices=shuffled_indices[count:count+bs]\n        minibatch_data =  X_train[indices].unsqueeze(dim=1)\n        minibatch_label=  y_train[indices]\n        \n        minibatch_data=minibatch_data.to(device)\n        minibatch_label=minibatch_label.to(device)\n        \n        \n        inputs = (minibatch_data - mean)/std    \n        \n        inputs.requires_grad_()\n\n        scores=net( inputs ) \n\n        loss =  criterion( scores , minibatch_label) \n        #print(loss)\n          \n        loss.backward()\n        \n        optimizer.step()\n        \n\n       \n        \n        running_loss += loss.detach().item()\n        \n        error = get_error( scores.detach() , minibatch_label)\n        running_error += error.item()\n        \n        num_batches+=1       \n    \n    if epoch % 2 == 1:\n            torch.save(net.state_dict(), f'./{epoch}.pth')\n    \n    \n    \n    total_loss = running_loss/num_batches\n    total_error = running_error/num_batches\n    \n    \n    print('epoch=',epoch,'\\t lr=', my_lr  ,'\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n    testing_e = eval_on_test_set()\n    print( 'error rate on test set =', testing_e*100 ,'percent')\n    print(' ')\n    training_error.append(total_error)\n    testing_error.append(testing_e)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:02:51.322103Z","iopub.execute_input":"2021-11-14T12:02:51.322383Z","iopub.status.idle":"2021-11-14T12:09:52.729393Z","shell.execute_reply.started":"2021-11-14T12:02:51.322352Z","shell.execute_reply":"2021-11-14T12:09:52.728575Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"plot the training and testing error","metadata":{}},{"cell_type":"code","source":"plt.plot(training_error, 'darkorange')\nplt.plot(testing_error, 'navajowhite')\nplt.xlabel(\"Training epoch\")\nplt.ylabel(\"Training loss\")\nplt.title(\"Training epoch to loss\")\nprint(np.asarray(testing_error).min())","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:11:53.416214Z","iopub.execute_input":"2021-11-14T12:11:53.417027Z","iopub.status.idle":"2021-11-14T12:11:53.694537Z","shell.execute_reply.started":"2021-11-14T12:11:53.416979Z","shell.execute_reply":"2021-11-14T12:11:53.693041Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"a simple demonstration of the predicted probability of the network ","metadata":{}},{"cell_type":"code","source":"def eval_on_test_set():\n    bs =1\n    running_error=0\n    num_batches=0\n\n    for i in range(1,2,bs):\n\n        minibatch_data =  X_test[i:i+bs].unsqueeze(dim=1)\n        minibatch_label= y_test[i:i+bs]\n\n        minibatch_data=minibatch_data.to(device)\n        minibatch_label=minibatch_label.to(device)\n        \n        inputs = (minibatch_data - mean)/std   \n\n        scores=net( inputs ) \n\n        error = get_error( scores , minibatch_label)\n\n        running_error += error.item()\n\n        num_batches+=1\n\n\n    total_error = running_error/num_batches\n    return total_error\ndef get_error( scores , labels ):\n    \n    x = []\n    x.append(\"sad\")\n    x.append(\"neutral\")\n    x.append(\"angry\")\n    x.append(\"surprise\")\n    x.append(\"fear\")\n    x.append(\"calm\")\n    x.append(\"happy\")\n    x.append(\"disgust\")\n    \n    \n    \n    bs=scores.size(0)\n\n    predicted_labels = scores.argmax(dim=1)\n\n    indicator = (predicted_labels == labels)\n    num_matches=indicator.sum()\n    \n    y = []\n    temp = scores[0]\n    for item in temp:\n        y.append(item.item())\n    \n    plt.scatter(x,y,200)\n    plt.scatter(x[y.index(max(y))],max(y),200)\n    plt.xlabel(\"Emotions\")\n    plt.ylabel(\"Probability\")\n    plt.title(\"Predicted probability\")\n    \n    \n    return 1-num_matches.float()/bs \n\neval_on_test_set()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T12:12:50.711661Z","iopub.execute_input":"2021-11-14T12:12:50.712374Z","iopub.status.idle":"2021-11-14T12:12:50.957581Z","shell.execute_reply.started":"2021-11-14T12:12:50.712324Z","shell.execute_reply":"2021-11-14T12:12:50.956797Z"},"trusted":true},"execution_count":30,"outputs":[]}]}